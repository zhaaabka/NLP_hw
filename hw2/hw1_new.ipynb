{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1N_V367bf-0",
        "outputId": "fcd62f1e-1fe6-4cc7-eea8-d1a9ff3ae5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fake_useragent in /usr/local/lib/python3.7/dist-packages (0.1.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install fake_useragent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tODViEO5S1fo",
        "outputId": "b9453c3f-6414-4926-d3a8-25fdacb804e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой функции вытаскиваем ссылки на фильмы, чтобы потом смочь из каждого фильма выкачать отзывы на него."
      ],
      "metadata": {
        "id": "r8JRNCT5celp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SceRhhtEiMnp"
      },
      "outputs": [],
      "source": [
        "def get_films(year):\n",
        "  links = []\n",
        "\n",
        "  year = str(year)\n",
        "  response = session.get(f\"https://www.metacritic.com/browse/movies/score/metascore/year/filtered/netflix?year_selected={year}&sort=desc&view=detailed\", headers={'User-Agent': ua.random})\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  films = soup.find_all('tr')\n",
        "  for film in films:\n",
        "    link = film.find('a', {'class': 'title'})\n",
        "    if link is not None:\n",
        "      link = link.attrs['href']\n",
        "      links.append(link)\n",
        "  return links"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой длинной (простите, короче не вышло) функции вытаскиваем отзывы на определенный фильм. И сразу же распихиваем, положительный или отрицательный отзыв. Для простоты я решила не брать нейтральные (те, у которых оценка >= 4 и <= 6)."
      ],
      "metadata": {
        "id": "D9_L0UxkcvDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reviews(link):\n",
        "  response = session.get(f'https://www.metacritic.com{link}/user-reviews', headers={'User-Agent': ua.random})\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  reviews = soup.find_all('div', {'class': 'review pad_top1'})\n",
        "  cnt = 1\n",
        "\n",
        "  positives = []\n",
        "  negatives = []\n",
        "  scores = ['negative', 'positive', 'mixed']\n",
        "  for review in reviews:\n",
        "    if cnt > 300:\n",
        "      break\n",
        "    cnt += 1\n",
        "    text = review.find('span', {'class': 'blurb blurb_expanded'})\n",
        "    if text is None:\n",
        "      text = review.find('div', {'class': 'review_body'})\n",
        "      text = text.find('span')\n",
        "      if text is not None:\n",
        "        text = text.text\n",
        "        if type(text) is not str:\n",
        "          text = text.text\n",
        "    f = False\n",
        "    for i in range(len(scores)):\n",
        "      score = review.find('div', {'class': f'metascore_w user large movie {scores[i]} indiv'})\n",
        "      if score is not None and text is not None:\n",
        "        f = True\n",
        "        score = int(score.text)\n",
        "        if score < 4:\n",
        "          negatives.append(text)\n",
        "        if score > 6:\n",
        "          positives.append(text)\n",
        "    if not f:\n",
        "      score = review.find('div', {'class': 'metascore_w user large movie positive indiv perfect'})\n",
        "      if score is not None and text is not None:\n",
        "        positives.append(text)\n",
        "  return positives, negatives"
      ],
      "metadata": {
        "id": "6pEaT3tBQTBR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В парсинге отзывов часто бывали какие-то не до идеального конча выкачанные тексты (какие-то html-теги оставались все еще), поэтому надо было все почистить."
      ],
      "metadata": {
        "id": "TtkkSZcjc_yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  return cleantext"
      ],
      "metadata": {
        "id": "mbArXx6SORw7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут происходит токенизация и лемматизация текстов (а еще для tests ниже я парсю каждый отзыв, т.е. деление на отзывы сохраняется, а для данных для \"обучения\" я просто создаю сразу массив лемм, чтобы дальше удобнее было работать)"
      ],
      "metadata": {
        "id": "NAfNj3IhdMgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning(texts, f):\n",
        "  cleaned_texts = []\n",
        "  for text in texts:\n",
        "    sw = stopwords.words('english')\n",
        "    morph = MorphAnalyzer()\n",
        "    words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
        "    filtered = [w for w in words if w not in sw]\n",
        "    ngramms = chunker(text)\n",
        "    filtered.extend(ngramms)\n",
        "    if f:\n",
        "      cleaned_texts.extend(filtered)\n",
        "    else:\n",
        "      cleaned_texts.append(filtered)\n",
        "  return cleaned_texts"
      ],
      "metadata": {
        "id": "OTXnjH0ZSmY1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой функции находим множество слов, которые встречаются в А, но не встречаются в В."
      ],
      "metadata": {
        "id": "NJVcQ7JddpEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sets(list_A, list_B):\n",
        "  A = set(list_A)\n",
        "  B = set(list_B)\n",
        "  return A.difference(A.intersection(B))"
      ],
      "metadata": {
        "id": "XoewoivnZnPn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Чанкер\n",
        "Я ищу в нем n-gramm'ы: NEG + глагол (т.е. n't + verb), сочетания типа hardly/barely + глагол (\"It hardly represents any historic events...\"), а так же pleasure + INF.\n",
        "\n",
        "Хотя spacy я определила как лучший морф анализатор для РУССКОГО, так уж вышло, что первая дз была на английском, так что использовать все равно буду его.\n",
        "\n",
        "Собственно, я просто прогоняю через чанкер уже очищенные тексты каждого отзыва и добавляю потом в общие листы positives, negatives и test. То есть, positives - лист, где лежат просто леммы слов, а так же n-граммы, аналогично для negatives, в tests хранятся массивы, где каждый массив - отзыв, и в нем лежат так же леммы и n-граммы. Потом все превращается в сеты и выполняются всякие операции с множествами."
      ],
      "metadata": {
        "id": "3FLhMLwM13yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunker(text):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(text)\n",
        "\n",
        "  ngramms = []\n",
        "  for i in range(len(doc) - 1):\n",
        "    if str(doc[i]) == \"n't\" and str(doc[i + 1].pos) == \"VERB\":\n",
        "      ngramms.append(str(doc[i]) + \" \" + str(doc[i + 1]))\n",
        "    if (str(doc[i]) == \"hardly\" or str(doc[i]) == \"barely\") and str(doc[i + 1].pos) == \"VERB\":\n",
        "      ngramms.append(doc[i] + \" \" + doc[i + 1])\n",
        "  for i in range(len(doc) - 2):\n",
        "    if str(doc[i]) == \"pleasure\" and str(doc[i + 1]) == \"to\" and str(doc[i + 2].pos) == \"VERB\":\n",
        "      ngramms.append(str(doc[i]) + \" \" + str(doc[i + 1]) + \" \" + str(doc[i + 2]))\n",
        "  return ngramms"
      ],
      "metadata": {
        "id": "cYxJTe3NlSRJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "crktdp4Ffd1l"
      },
      "outputs": [],
      "source": [
        "from fake_useragent import UserAgent\n",
        "from random import randint\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "j-yB0KyRvF9I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r6RdtiYvHND",
        "outputId": "35d98eb2-b3c8-478c-9d27-5c0e1f92f3fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-11 20:29:51.851040: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "euSbtSTMhrYI"
      },
      "outputs": [],
      "source": [
        "ua = UserAgent(verify_ssl=False)\n",
        "session = requests.session()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я взяла один год, потому что иначе выходило слишком много данных и программа очень долго работала..."
      ],
      "metadata": {
        "id": "KuKnUVWxd1iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links = get_films(2008)"
      ],
      "metadata": {
        "id": "PkZsqR70UvSU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = []\n",
        "negatives = []"
      ],
      "metadata": {
        "id": "JFx8h4TJPRHF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for link in links:\n",
        "  p, n = get_reviews(link)\n",
        "  positives.extend(p)\n",
        "  negatives.extend(n)"
      ],
      "metadata": {
        "id": "fSlmm3oOSKfh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ9jbuBIVhuD",
        "outputId": "a92f1581-0662-4025-d33b-388ff8f9f399"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = int(min(len(positives), len(negatives)) / 4)"
      ],
      "metadata": {
        "id": "kaQyr8TfY8pt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут делаю три листа: для \"обучения\" (positives и negatives) и для теста (test), а так же \"правильные ответы\" к тесту."
      ],
      "metadata": {
        "id": "stJSn-1cd78G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = []\n",
        "test.extend(positives[(length * 3):(length * 4)])\n",
        "y_true = [1 for i in range(len(test))]\n",
        "y_true.extend([0 for j in range(len(test))])\n",
        "test.extend(negatives[(length * 3):(length * 4)])"
      ],
      "metadata": {
        "id": "mZrOhHNnGk71"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = positives[:(length * 3)]\n",
        "negatives = negatives[:(length * 3)]"
      ],
      "metadata": {
        "id": "an4qwcY9G2VD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяю, что по длинам все сошлось."
      ],
      "metadata": {
        "id": "OPHvcA1ieI6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(positives))\n",
        "print(len(negatives))\n",
        "print(len(test))\n",
        "print(len(y_true))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmxN9ZK1a65p",
        "outputId": "c6f21486-7858-4f2f-a0db-ac4e40ae149e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "267\n",
            "267\n",
            "178\n",
            "178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чищу оставшиеся html-теги"
      ],
      "metadata": {
        "id": "_7aMUoF3eUdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(positives)):\n",
        "  if type(positives[i]) is not str:\n",
        "    positives[i] = cleanhtml(str(positives[i]))"
      ],
      "metadata": {
        "id": "dZT2s2zaH5SF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(negatives)):\n",
        "  if type(negatives[i]) is not str:\n",
        "    negatives[i] = cleanhtml(str(negatives[i]))"
      ],
      "metadata": {
        "id": "UW-Rbx9NQj3h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test)):\n",
        "  if type(test[i]) is not str:\n",
        "    test[i] = cleanhtml(str(test[i]))"
      ],
      "metadata": {
        "id": "0eZ7R_EeQoSj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = text_cleaning(positives, True)\n",
        "negatives = text_cleaning(negatives, True)\n",
        "test = text_cleaning(test, False)"
      ],
      "metadata": {
        "id": "NKHAQiJeDA1K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "JQ56g3GOZTS7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = Counter(positives)\n",
        "negatives = Counter(negatives)"
      ],
      "metadata": {
        "id": "G344tFvHbnVR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбираю во множествах те слова, которые встречаются >= 10 раз. Кажется, если сначала выкинуть пересение между множествами, а потом смотреть на частоты, то выйдет плохо (например, у нас может встретиться perfect в отрицательном отзыве один раз, и тогда мы его выкинем). А если возьмем сначала просто самые частотные слова и в них уже пересечение выкинем, то такой ситуации не будет."
      ],
      "metadata": {
        "id": "cCu0nCg-efIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_set = []\n",
        "for i in positives.most_common(100):\n",
        "  if i[1] < 10:\n",
        "    break\n",
        "  pos_set.append(i[0])"
      ],
      "metadata": {
        "id": "UeKjaOMFZV5v"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_set = []\n",
        "for i in negatives.most_common(100):\n",
        "  if i[1] < 10:\n",
        "    break\n",
        "  neg_set.append(i[0])"
      ],
      "metadata": {
        "id": "A40bgHC3WxE-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_pos = sets(pos_set, neg_set)"
      ],
      "metadata": {
        "id": "6h8VkiEpbd7T"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_neg = sets(neg_set, pos_set)"
      ],
      "metadata": {
        "id": "i-bUXKxQXhiP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []"
      ],
      "metadata": {
        "id": "13PvIglHXt7V"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаю сколько слов в отзыве входят в \"положительное\" множество и в \"отрицательное\". Каких больше, таким и будем считать отзыв."
      ],
      "metadata": {
        "id": "-5rUyde4jLZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text in test:\n",
        "  cnt_pos = 0\n",
        "  cnt_neg = 0\n",
        "  for w in text:\n",
        "    if w in only_pos:\n",
        "      cnt_pos += 1\n",
        "    if w in only_neg:\n",
        "      cnt_neg += 1\n",
        "  y_pred.append(int(cnt_pos > cnt_neg))"
      ],
      "metadata": {
        "id": "IIMKH3D4Z1nK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "kzgC1JTUaigq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy\n",
        "В итоге вышла хуже, чем была - 0.6612903225806451 (см файл первой дз)"
      ],
      "metadata": {
        "id": "kDAfTSeHjdUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM46ivI9ap91",
        "outputId": "fa8995fc-0539-444d-e99a-04ae1aa43f9c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6404494382022472"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}