{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1N_V367bf-0",
        "outputId": "20f54a11-4c84-49b8-9e9a-e24316b5b880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fake_useragent in /usr/local/lib/python3.7/dist-packages (0.1.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install fake_useragent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tODViEO5S1fo",
        "outputId": "c83c0874-11e4-468a-891c-e9c1d46d4be7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой функции вытаскиваем ссылки на фильмы, чтобы потом смочь из каждого фильма выкачать отзывы на него."
      ],
      "metadata": {
        "id": "r8JRNCT5celp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SceRhhtEiMnp"
      },
      "outputs": [],
      "source": [
        "def get_films(year):\n",
        "  links = []\n",
        "\n",
        "  year = str(year)\n",
        "  response = session.get(f\"https://www.metacritic.com/browse/movies/score/metascore/year/filtered/netflix?year_selected={year}&sort=desc&view=detailed\", headers={'User-Agent': ua.random})\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  films = soup.find_all('tr')\n",
        "  for film in films:\n",
        "    link = film.find('a', {'class': 'title'})\n",
        "    if link is not None:\n",
        "      link = link.attrs['href']\n",
        "      links.append(link)\n",
        "  return links"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой длинной (простите, короче не вышло) функции вытаскиваем отзывы на определенный фильм. И сразу же распихиваем, положительный или отрицательный отзыв. Для простоты я решила не брать нейтральные (те, у которых оценка >= 4 и <= 6)."
      ],
      "metadata": {
        "id": "D9_L0UxkcvDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reviews(link):\n",
        "  response = session.get(f'https://www.metacritic.com{link}/user-reviews', headers={'User-Agent': ua.random})\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  reviews = soup.find_all('div', {'class': 'review pad_top1'})\n",
        "  cnt = 1\n",
        "\n",
        "  positives = []\n",
        "  negatives = []\n",
        "  scores = ['negative', 'positive', 'mixed']\n",
        "  for review in reviews:\n",
        "    if cnt > 300:\n",
        "      break\n",
        "    cnt += 1\n",
        "    text = review.find('span', {'class': 'blurb blurb_expanded'})\n",
        "    if text is None:\n",
        "      text = review.find('div', {'class': 'review_body'})\n",
        "      text = text.find('span')\n",
        "      if text is not None:\n",
        "        text = text.text\n",
        "        if type(text) is not str:\n",
        "          text = text.text\n",
        "    f = False\n",
        "    for i in range(len(scores)):\n",
        "      score = review.find('div', {'class': f'metascore_w user large movie {scores[i]} indiv'})\n",
        "      if score is not None and text is not None:\n",
        "        f = True\n",
        "        score = int(score.text)\n",
        "        if score < 4:\n",
        "          negatives.append(text)\n",
        "        if score > 6:\n",
        "          positives.append(text)\n",
        "    if not f:\n",
        "      score = review.find('div', {'class': 'metascore_w user large movie positive indiv perfect'})\n",
        "      if score is not None and text is not None:\n",
        "        positives.append(text)\n",
        "  return positives, negatives"
      ],
      "metadata": {
        "id": "6pEaT3tBQTBR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В парсинге отзывов часто бывали какие-то не до идеального конча выкачанные тексты (какие-то html-теги оставались все еще), поэтому надо было все почистить."
      ],
      "metadata": {
        "id": "TtkkSZcjc_yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  return cleantext"
      ],
      "metadata": {
        "id": "mbArXx6SORw7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут происходит токенизация и лемматизация текстов (а еще для tests ниже я парсю каждый отзыв, т.е. деление на отзывы сохраняется, а для данных для \"обучения\" я просто создаю сразу массив лемм, чтобы дальше удобнее было работать)"
      ],
      "metadata": {
        "id": "NAfNj3IhdMgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning(texts, f):\n",
        "  cleaned_texts = []\n",
        "  for text in texts:\n",
        "    sw = stopwords.words('english')\n",
        "    morph = MorphAnalyzer()\n",
        "    words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
        "    filtered = [w for w in words if w not in sw]\n",
        "    if f:\n",
        "      cleaned_texts.extend(filtered)\n",
        "    else:\n",
        "      cleaned_texts.append(filtered)\n",
        "  return cleaned_texts"
      ],
      "metadata": {
        "id": "OTXnjH0ZSmY1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой функции находим множество слов, которые встречаются в А, но не встречаются в В."
      ],
      "metadata": {
        "id": "NJVcQ7JddpEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sets(list_A, list_B):\n",
        "  A = set(list_A)\n",
        "  B = set(list_B)\n",
        "  return A.difference(A.intersection(B))"
      ],
      "metadata": {
        "id": "XoewoivnZnPn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "crktdp4Ffd1l"
      },
      "outputs": [],
      "source": [
        "from fake_useragent import UserAgent\n",
        "from random import randint\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "euSbtSTMhrYI"
      },
      "outputs": [],
      "source": [
        "ua = UserAgent(verify_ssl=False)\n",
        "session = requests.session()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я взяла один год, потому что иначе выходило слишком много данных и программа очень долго работала..."
      ],
      "metadata": {
        "id": "KuKnUVWxd1iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links = get_films(2008)"
      ],
      "metadata": {
        "id": "PkZsqR70UvSU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = []\n",
        "negatives = []"
      ],
      "metadata": {
        "id": "JFx8h4TJPRHF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for link in links:\n",
        "  p, n = get_reviews(link)\n",
        "  positives.extend(p)\n",
        "  negatives.extend(n)"
      ],
      "metadata": {
        "id": "fSlmm3oOSKfh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ9jbuBIVhuD",
        "outputId": "bb94590e-19f2-4e8f-eca3-240c94b18736"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = int(min(len(positives), len(negatives)) / 4)"
      ],
      "metadata": {
        "id": "kaQyr8TfY8pt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут делаю три листа: для \"обучения\" (positives и negatives) и для теста (test), а так же \"правильные ответы\" к тесту."
      ],
      "metadata": {
        "id": "stJSn-1cd78G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = []\n",
        "test.extend(positives[(length * 3):(length * 4)])\n",
        "y_true = [1 for i in range(len(test))]\n",
        "y_true.extend([0 for j in range(len(test))])\n",
        "test.extend(negatives[(length * 3):(length * 4)])"
      ],
      "metadata": {
        "id": "mZrOhHNnGk71"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = positives[:(length * 3)]\n",
        "negatives = negatives[:(length * 3)]"
      ],
      "metadata": {
        "id": "an4qwcY9G2VD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяю, что по длинам все сошлось."
      ],
      "metadata": {
        "id": "OPHvcA1ieI6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(positives))\n",
        "print(len(negatives))\n",
        "print(len(test))\n",
        "print(len(y_true))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmxN9ZK1a65p",
        "outputId": "3a9450db-5835-42af-b375-d34310c9aea8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186\n",
            "186\n",
            "124\n",
            "124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чищу оставшиеся html-теги"
      ],
      "metadata": {
        "id": "_7aMUoF3eUdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(positives)):\n",
        "  if type(positives[i]) is not str:\n",
        "    positives[i] = cleanhtml(str(positives[i]))"
      ],
      "metadata": {
        "id": "dZT2s2zaH5SF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(negatives)):\n",
        "  if type(negatives[i]) is not str:\n",
        "    negatives[i] = cleanhtml(str(negatives[i]))"
      ],
      "metadata": {
        "id": "UW-Rbx9NQj3h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test)):\n",
        "  if type(test[i]) is not str:\n",
        "    test[i] = cleanhtml(str(test[i]))"
      ],
      "metadata": {
        "id": "0eZ7R_EeQoSj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = text_cleaning(positives, True)\n",
        "negatives = text_cleaning(negatives, True)\n",
        "test = text_cleaning(test, False)"
      ],
      "metadata": {
        "id": "NKHAQiJeDA1K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "JQ56g3GOZTS7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = Counter(positives)\n",
        "negatives = Counter(negatives)"
      ],
      "metadata": {
        "id": "G344tFvHbnVR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбираю во множествах те слова, которые встречаются >= 10 раз. Кажется, если сначала выкинуть пересение между множествами, а потом смотреть на частоты, то выйдет плохо (например, у нас может встретиться perfect в отрицательном отзыве один раз, и тогда мы его выкинем). А если возьмем сначала просто самые частотные слова и в них уже пересечение выкинем, то такой ситуации не будет."
      ],
      "metadata": {
        "id": "cCu0nCg-efIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_set = []\n",
        "for i in positives.most_common(100):\n",
        "  if i[1] < 10:\n",
        "    break\n",
        "  pos_set.append(i[0])"
      ],
      "metadata": {
        "id": "UeKjaOMFZV5v"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_set = []\n",
        "for i in negatives.most_common(100):\n",
        "  if i[1] < 10:\n",
        "    break\n",
        "  neg_set.append(i[0])"
      ],
      "metadata": {
        "id": "A40bgHC3WxE-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_pos = sets(pos_set, neg_set)"
      ],
      "metadata": {
        "id": "6h8VkiEpbd7T"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_neg = sets(neg_set, pos_set)"
      ],
      "metadata": {
        "id": "i-bUXKxQXhiP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []"
      ],
      "metadata": {
        "id": "13PvIglHXt7V"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаю сколько слов в отзыве входят в \"положительное\" множество и в \"отрицательное\". Каких больше, таким и будем считать отзыв."
      ],
      "metadata": {
        "id": "-5rUyde4jLZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text in test:\n",
        "  cnt_pos = 0\n",
        "  cnt_neg = 0\n",
        "  for w in text:\n",
        "    if w in only_pos:\n",
        "      cnt_pos += 1\n",
        "    if w in only_neg:\n",
        "      cnt_neg += 1\n",
        "  y_pred.append(int(cnt_pos > cnt_neg))"
      ],
      "metadata": {
        "id": "IIMKH3D4Z1nK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "kzgC1JTUaigq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну и понятно, что accuracy очень не очень, но все равно неплохо - выше, чем я ожидала)"
      ],
      "metadata": {
        "id": "kDAfTSeHjdUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM46ivI9ap91",
        "outputId": "bf90d920-625d-4bd0-a0f0-ae5558ad0623"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6612903225806451"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как улучшить:\n",
        "\n",
        "1. Понятно, увеличить корпус (но это я реализовывать не буду, слишком долго будет работать - функция токенизации и лемматизации довольно долго работает...)\n",
        "\n",
        "2. Можно попробовать учитывать отрицания (для отрицательных отзывов скорее?)\n",
        "\n",
        "3. Использовать метрику tf-idf. Там, помимо частотности самого слова в документах - отзывах, учитывается так же и количество документов, в которых это слово встречается. Это поможет меньше учитывать слова, которые часто встретились в малом количества отзывов (т.е. это скорее какая-то характеристика письма человека, а не характеристика фильма), типа в одном отзыве несколько раз употребилось одно и то же слово, а в других оно почти не встречалось или встречалось по одному разу, например.\n",
        "\n",
        "4. Выкачать словарь оценочных слов (возможно, как-то попытаться полувручную это сделать?). Плохие - bad, awful, boring и т.д., хорошие - wonderful, awesome, interesting и т.д.\n",
        "\n",
        "5. В полученных мною множествах было много мусора, который встречался часто. Например в \"отрицательном\" сете очень часто встречалось, например, слово vampire. Такое может быть, что жанровые (и вообще какие-то описательные штуки про фильм) встретились только в одной оценочной категории (особенно, если корпус не такой большой), поэтому можно попытаться создать словарь таких типа \"жанровых\" слов и выкидывать их как стоп-слова, чтобы они не засоряли картину."
      ],
      "metadata": {
        "id": "NqLG0fIvjlml"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}